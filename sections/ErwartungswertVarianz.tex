\section{Erwartungswert und Varianz}

\subsection{Erwartungswert}
\begin{minipage}{0.49\textwidth}
	Sei $X$ eine Funktion auf $\Omega$, und lasse sich $\Omega$ in endlich viele Ereignisse $A_i$ zerlegen, auf denen $X(\omega)$ konstant ist, dann ist der Erwartungswert von $X$ 
	\[ \text{Erwartungswert} = \sum \text{Wert} \cdot \text{Wahrscheinlichkeit}\] 
	\[\boxed{E(X)=\sum\limits_{i=0}^n \underbrace{X(A_i)}_{\text{Wert}}\cdot 		\underbrace{P(A_i)}_{\text{W'keit}}}\]
	\[E(X) = \int\limits_{-\infty}^x x \cdot \varphi(x) dx$ mit $\varphi(x) = \text{Dichtefunktion}\] 
	\subsubsection{Rechenregeln}
	$E(X+Y)=E(X)+E(Y)$ \\
	$E(\lambda X + \mu) = \lambda \cdot E(X) + \mu \quad \lambda, \mu \in
	\mathbb{R}$ \\
	$E(XY) = E(X)\cdot E(Y)$ \quad  wenn X,Y unabhängig sind \\
\end{minipage}
\hspace{0.02\textwidth}
\begin{minipage}{0.49\textwidth}
	\input{tikz/ErwartungswertVarianz}
\end{minipage}

\hrule

\begin{minipage}{0.42\textwidth}
	\vspace{2mm}
	\subsection{Varianz}
	$\boxed{var(X)=E(X^2)-E(X)^2}= \:E[(X-E(X))^2]$\\[2pt]
	\textbf{Standardabweichung} $\sigma = \sqrt{var(X)}$\\[2pt]
	
	\textcolor{red}{\textbf{Achtung:}} Wenn endliche Werte vorliegen muss die Formel der Stichprobenvarianz angewendet werden, Kapitel \ref{Stichprobenvarianz} Seite \pageref{Stichprobenvarianz}.

	\subsubsection{Kovarianz}
	$cov(X,Y)=E(XY)-E(X)E(Y)=\hspace{-0.8cm}\underbrace{0}_{\text{falls X,Y unabhängig}}$\\[2pt]
	Ist die Kovarianz positiv so tendieren höhere $X$-Werte zu höheren $Y$-Werten.
	\vspace{.2cm}
\end{minipage}
\hspace{0.02\textwidth}
\begin{minipage}{0.56\textwidth}
	\vspace{2mm}
	\subsubsection{Rechenregeln}
		$var(\lambda X)=\lambda^2 var(X) \qquad $ $\lambda, \mu \in \mathbb{R}$\\[4pt]
		$var(X_1+X_2+\ldots+X_n) \neq var(n X)$ \\[4pt]
		$var(X+Y)= 
			\begin{cases}
		  		var(X)+var(Y) & \text{(X,Y unabh.)}\\                
		  		var(X) + var(Y) + 2 \cdot cov(X,Y) & \text{(X,Y abhängig)}\\
			\end{cases} $ \\[4pt]
		$var(X Y)= var(Y)var(X)+var(Y)E(X)^2+var(X)E(Y)^2$ \\
	\vspace{.2cm}
\end{minipage}

\hrule

\subsection{Erwartungswert und Varianz des arithmetischen Mittels}
Es sei eine Folge von unabhängigen Zufallsvariablen $X_1, X_2, \ldots , X_n$ mit gleichem Erwartungswert $ \mu $ und gleicher Varianz $ \sigma^2 $ gegeben. \\
\begin{tabular}{m{0.33\textwidth} m{0.33\textwidth} m{0.33\textwidth}}
	Mittelwert: $M_n=\frac{X_1+\ldots+X_n}{n}$ &
	Erwartungswert: $E(X)=E(M_n) = \mu$  &
	Varianz: $var(M_n)=\frac{1}{n}var(X) = \frac{\sigma ^2}{n} $
\end{tabular}
\vspace{1mm}
\hrule

\subsection{Satz von Tschebyscheff}
\begin{tabular}{ll}
  $P(\left| X-E(X) \right|>\varepsilon)\leq\dfrac{var(X)}{\varepsilon^2}$ &
  Wahrscheinlichkeit, dass $X$ um mehr als $\varepsilon$ vom Erwartungswert $E(X)$ abweicht.\\
  $P(|M_{n}-\mu|>\varepsilon)\leq \frac{\sigma^{2}}{\varepsilon^{2}n} $ &
  W'keit, dass $M_{n}$ von $n$ unab. ZV mit Mittelwert $\mu$ und Varianz $\sigma^{2}$ mehr als $\varepsilon$ von $\mu$ abweicht.
\end{tabular}

\begin{minipage}[t]{9cm}
  \subsection{Regression}
  \begin{tabular}{ll}
    Allgemein: & X,Y Zufallsvariable \\
    Gesucht: & Regressionsgerade $y=ax+b$ mit min. Fehler \\
    Fehler: & $E(Y-(aX+b))=0$ \\
  \end{tabular} \\
 
  \textbf{Regressionskoeffizient r} \\
  $r$ ist ein Mass für die Qualität der Regression (standardisiert) \\
  $r^2=\dfrac{cov(X,Y)^2}{var(X)var(Y)}=a^2\cdot\dfrac{var(X)}{var(Y)}$ \\  \\
  Liegt $r$ nahe bei $1$ $\widehat{=}$ gute Approximation\\ \\
 
  \textbf{Mittlerer quadratischer Fehler} \\
  $\Delta^2 = var(Y)(1-r^2) =
  var(Y)\left(1-\dfrac{cov(X,Y)^2}{var(X)var(Y)}\right) $ \\
\end{minipage}
\begin{minipage}[t]{10cm}
  \textbf{Vorgehen:}
  \textcolor{blue}{mit Fehlerberechnung}
	\begin{enumerate}
		\item Tabelle mit bekannten Werten aufstellen:\\
		\scriptsize
		Vorlage-Tabelle ist auf \href{https://github.com/RostBau/WrStat/tree/master/Zusatzblaetter/LineareRegression}{GitHub}\\ %TODO Link überprüfen
		\normalsize
  		\begin{tabular}{|l||l|l||l|l||l|}
  		  \hline
        \textbf{$k$} & \textbf{$x$} & \textbf{$x^2$} & \textbf{$y$} &
  		  \textcolor{blue}{\textbf{$y^2$}} & \textbf{$xy$} \\
  		  \hline \hline
  		  $1$ & $x_1$ & $x_1^2$ & $y_1$ & \textcolor{blue}{$y_1^2$} & $x_1y_1$ \\
  		  \hline
  		  $\vdots$ & $\vdots$ & $\vdots$ & $\vdots$ & \textcolor{blue}{$\vdots$} &
  		  $\vdots$ \\\hline $n$ & $x_n$ & $y_n^2$ & $y_n$ & \textcolor{blue}{$y_n^2$} & $x_ny_n$ \\
  		  \hline
  		  \hline
  		  $\sum$ & $\sum x_k$ & $\sum x_k^2$ & $\sum y_k$ & \textcolor{blue}{$\sum
  		  y_k^2$} & $\sum x_ky_k$ \\
  		  \hline $E$ & $\frac{\sum x_k}{n}$ & $\frac{\sum x_k^2}{n}$ & $\frac{\sum
  		  y_k}{n}$ & \textcolor{blue}{$\frac{\sum y_k^2}{n}$} & $\frac{\sum x_ky_k}{n}$ \\
  		  \hline
  		\end{tabular} 
		\item Varianzen, Kovarianz berechnen: \\
		  $var(X) = E(X^2) - E^2(X)$ \\
		  \textcolor{blue}{$var(Y) = E(Y^2) - E^2(Y)$} \\
		  $cov(X,Y) = E(XY) - E(X)E(Y)$
		\item Koeffizienten \textcolor{blue}{und Fehler} der Gerade berechnen: \\
		  $a=\dfrac{cov(X,Y)}{var(X)}$
		  \textcolor{blue}{$\qquad\Delta^2=var(Y)\left(1-\dfrac{cov(X,Y)^2}
		  {var(X)var(Y)}\right) $} \\
		  $b=E(Y)-aE(X)$
		\item Gerade: \\
		$y=ax+b$
	\end{enumerate}
\end{minipage}
\vspace{.2cm}
\hrule
\subsubsection{Beispiel Regression}
\begin{minipage}{0.49\textwidth}
	Je wärmer es ist, desto schneller zirpen die Grillen.\\
	Folgende Daten wurden erhoben:\\
	\begin{tabular}{c|c}
		$T\left[^{\circ} \mathrm{C}\right]$ & $N[\text { Zirpen/}15 \text { Sekunden}]$\\
		\hline
		15 & 20\\
		19 & 23\\
		22 & 30\\
		25 & 39\\
		\hline	
	\end{tabular}\\[5pt]
	Es wird vermutet, dass die Anzahl der Zirplaute pro 15 Sekunden linear von der Temperatur abhängt.	Finden Sie eine solche Gesetzmässigkeit und beurteilen Sie ihre Qualität.\\[5pt]
	
	\input{tikz/linRegression.tex}
\end{minipage}
\hspace{0.02\textwidth}
\begin{minipage}{0.49\textwidth}
	\begin{enumerate}
		\item Tabelle ausfüllen:\\
		\begin{tabular}{|l||l|l||l|l||l|}
			\hline
			\textbf{$k$} & \textbf{$t$} & \textbf{$t^2$} & \textbf{$n$} &
			\textbf{$n^2$} & \textbf{$tn$} \\
			\hline \hline
			$1$ & $15$ & $225$ & $20$ & $400$ & $300$ \\
			\hline
			$2$ & $19$ & $361$ & $23$ & $529$ &	$437$\\
			\hline
			$3$ & $22$ & $484$ & $30$ & $900$ &	$660$\\
			\hline
			$4$ & $25$ & $625$ & $39$ & $1521$ & $975$\\
			\hline
			\hline
			$\sum$ & $81$ & $1695$ & $112$ & $3350$ & $2372$ \\
			\hline 
			$E$ & $20.25$ & $423.75$ & $28$ & $837.5$ & $593$ \\
			\hline
		\end{tabular}
		\item Varianzen und Kovarianzen berechnen:\\
		$var(t) = E(t^2) - E^2(t) = 423.75-20.25^2 = 13.6875$\\
		$var(n) = E(n^2) - E^2(n) = 837.5 - 28^2 = 53.5$\\
		$cov(t, n) = E(tn) - E(t)E(n) = 593 - 20.25 \cdot 28 = 26$ 
		\item Koeffizienten und Fehler der Gerade berechnen:\\
		$a = \frac{cov(t, n)}{var(t)} = \frac{26}{13.6875} = 1.8995$\\
		$b = E(n) - aE(t) = 28 - 1.8995\cdot 20.25 = -10.4649$\\
		$r = \sqrt{\frac{cov(t, n)^{2}}{var(t) var(n)}} = \sqrt{\frac{26^2}{13.6875\cdot 53.5}} = 0.9608$	
	\end{enumerate}
\end{minipage}




\vspace{.2cm}
\hrule
